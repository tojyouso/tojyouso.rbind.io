---
title: Analysing the words I write in my journal
author: tojyouso
date: '2017-03-31'
tags:
  - Quantified Self
  - Text Analysis
slug: analysing-words-in-my-journal
---


```{r echo = F}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

One area of my quantified journey that I have struggled with tracking is my mood and feelings. I've tried [nomie](https://nomie.io) which is great, I've tried a couple of other mood tracker apps but after a while I lose motivation to record these things. They felt a bit meaningless because I had to record my mood at random points throughout the day, but I needed more context. I tried Evernote but it was too clunky and got in the way of how I normally use it; I also wanted something that was primarily mobile as I spend a lot of time out and about.

This problem, coupled with my long-time desire to journal my life brought me to try out [Day One](http://dayoneapp.com). I love it. I love the design of the app and how easy it is to use. It has markdown elements - I'm a sucker for markdown, latex, rmarkdown, all those kind of things! I can put pictures in it and it backs up to a server! Best of all, it exports as a JSON file. 

It's like having a twitter feed just for yourself. 

The only negative (and not even a real negative) is the price of the Mac app:

![](/images/day_one_files/day_one_mac_app.png)

But honestly, I think it would be worth it - it's a one off price, not a subscription. The only reason I haven't made the commitment is I'm not sure I'll still be on Mac in a year's time.

The plan is to add this as a section in my personal dashboard. But below, I've had a go at analysing the data and thrown up some possible tracking metrics. Let me know what you think!

```{r, message = F}
library(tidyverse)
library(stringr) 
library(ggcal) # for calendar plots
library(tidytext) # for tidy text sentiment and manipulation
library(jsonlite) # for json
library(lubridate)
library(hrbrthemes)
library(viridis)

as_at <- "20170329"
day_one <- fromJSON("/Users/mobolayo/Documents/R/data/day_one/Journal.json")
saveRDS(day_one, paste0("/Users/mobolayo/Documents/R/data/day_one/journal_", as_at, 
          ".JSON"))
# list of 2 so only need data element
day_one <- day_one[[2]]

# nested data frames so need to flatten them
day_one <- jsonlite::flatten(day_one)

day_one$date <- ymd(str_sub(day_one$creationDate, 1, 10))

# find hour and convert numeric - treat minutes as proportion of 60
day_one$hour_min <- as.numeric(str_sub(day_one$creationDate, 12, 13)) + as.numeric(str_sub(day_one$creationDate, 15, 16)) / 60

day_one$hour <- round(day_one$hour_min)

# days and months

day_one$month <- month(day_one$date, label = T)
day_one$day <- weekdays(day_one$date)

# entry length, character and word length
# plan to change to important word length not just any word length
day_one$char_length <- nchar(day_one$text)

# http://stackoverflow.com/questions/8920145/count-the-number-of-words-in-a-string-in-r
day_one$word_length <- str_count(day_one$text, "\\w+")
```

## When and how much do I journal?

### A. How much do I journal?

I started journalling the day I got my iPhone in Sept 2016. In fact, this is the first entry:

```{r}
day_one$text[1]
```

I was really excited haha! Since then I've written `r sum(day_one$word_length, na.rm = T)` words.

I tried to keep up the journalling and I succeeded for the first couple of months but it tailed off and I only started again in the new year.

```{r}

target_words <- 150

ggplot(data = day_one, aes(x = date, y = word_length)) +
  geom_col(fill = "#F98C0AFF", alpha = 0.4) +
  geom_hline(yintercept = target_words, colour = "#000004FF") +
  labs(x = "", y = "Number of words written everyday",
       title = "My journalling tailed off at the end of 2016",
       # subtitle = "Number of words written in daily journal",
        caption = "@tojyouso") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  theme_minimal() +
  theme(
        # axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20)) 
```

I wish I had recorded more during that end of year period, it was an important part of my life - my wife and I were considering a move from London to Oslo! (spoiler alert - I'm writing this on our new dining table in Oslo). Since then I've set my self a target of an average of `r target_words` words a days. This is how I track this monthly:

```{r}
as_tibble( data.frame(date = seq(floor_date(ymd(as_at), "month"), ceiling_date(ymd(as_at), "month") - 1, by = "day"), target = target_words)) %>% 
  left_join(day_one %>% 
              select(date, word_length) %>% 
              filter(date >= ymd("20170301"),
                !is.na(word_length)) %>%
              group_by(date) %>% 
              summarise(word_length = sum(word_length)), by = "date") %>% 
  mutate(word_length = ifelse(is.na(word_length), 0, word_length)) %>% 
  mutate_each(funs(cumsum), - date) %>% 
  gather(variable, word_length, -date) %>% 
  ggplot(aes(x = date, y = word_length, group = variable, colour = variable,
             linetype = variable)) +
  geom_line() +
  labs(x = "", y = "Cumulative number of words written",
       title = "I hit my target number of words this month",
       # subtitle = "Number of words written in daily journal",
        caption = "@tojyouso") +
  # scale_colour_ipsum() +
  scale_colour_manual(values = c("#000004FF", "#F98C0AFF"),
                      labels = c("Target", "Actual")) +
  scale_linetype_manual(values = c("dashed", "solid"),
                        labels = c("Target", "Actual")) +
  # scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  theme_minimal() +
  theme(legend.justification=c(1,0), legend.position=c(1,0), legend.title=element_blank()) +
  theme(
        # axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        # panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20)) 
```

It's not the end of the month yet and I have hit my target of `r target_words * 30` words!

I'm also trialling the new [ggcal package](https://github.com/jayjacobs/ggcal) as a way to show how often I journal. I like it! I have also moved to using the colour palette from the [viridis package](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html), great for those who are colour blind and I like how bright the colours are.

The calendar chart makes it really clear to see that I wrote a lot of words on the third Sunday of March. That was the last weekend we spent with our family and with our church in London before we moved to Oslo a few days later. I really wanted to capture as much as I could about that weekend.

```{r}
ggcal(day_one$date, day_one$word_length) +
  # scale_fill_gradient2(low="#4575b4", mid="#ffffbf", high="#d73027",
  #                      midpoint = 100,
  #                      na.value = "gray95") +
  scale_fill_viridis(option = "B", na.value = "#FCFFA4FF", direction = -1) +
  labs(title = "Number of words written in my journal",
       # subtitle = "Red is positive",
       caption = "@tojyouso") +
  theme( plot.title = element_text(face="bold", size = 20))
```

### B. When do I journal?

The great thing about having full dates and times attached to each journal entry is that I can look at the specific times during the day and week that I journal.

The distribution of times during the day surprised me a little bit. I was expecting to see my commuting hours coming out. I'm not sure why I journal so much around 8 o'clock. What am I usually doing at 8 in the evening? Eating dinner and watching T.V. I guess. It could also be the dreaded curse of small sample sizes - there are only about 250 notes.

```{r}

ggplot(data = day_one, aes(x = hour, weight = word_length)) +
  geom_bar(fill = "#F98C0AFF", alpha = 0.4) +
  labs(x = "Time of day", y = "Number of words written",
       title = "No surprise that I don't journal \nwhen I'm asleep",
       # subtitle = "",
        caption = "@tojyouso") +
  # scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  # theme_ipsum(grid = "Y") +
  theme_minimal() +
  theme(
        # axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20)) 

# day_one %>% filter(hour == 20)
```

4 a.m. is the only hour of the day I haven't journalled yet.

In terms of days in the week, I journal most on Sundays - again not surprised by that given that's usually my day of reflection. We also used to have a very long London underground journey to and from church without internet - so I used to journal then to pass time. Saturday is low because I'm probably busy doing something else!

```{r}

day_one$day <- factor(day_one$day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday",
                                                 "Thursday", "Friday", "Saturday"))
ggplot(data = day_one, aes(x = day, weight = word_length)) +
  geom_bar(fill = "#F98C0AFF", alpha = 0.4) +
  labs(x = NULL, y = "Number of words written",
       title = "I journal most on Sundays",
       # subtitle = "",
        caption = "@tojyouso") +
  # scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  # theme_ipsum(grid = "Y") +
  theme_minimal() +
  theme(
        # axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20)) 
```

That downward trend as the week progresses is random... Can't think of any reason why it would be like that.

## What do I journal about?

Now I've explored when and how I journal, I want to explore what I actually write. I used the amazing [tidytext package](http://tidytextmining.com) to do almost all of the following analysis.

First, let's look at my top ten words. No surprise that Steph is up there amongst the top given that's my wife's name. Day and time feature a lot, as do morning and night - I imagine they're to do with me describing a time period like `I had a great day` or `Last night was so much fun`.

*NB: I removed all stop words as well as "dayone" and "moment" as those two words our automatically added when a journal entry includes a picture*

```{r}
tidy_text <- day_one %>% 
  select(text, date) %>% 
  unnest_tokens(word, text, token = "words") 

# remove stop words
# TODO: remove "dayone" as well
data("stop_words")

stop_words <- rbind(stop_words, c("dayone", "custom"), c("moment", "custom"))
tidy_text <- tidy_text %>% 
  anti_join(stop_words)

tidy_text %>% 
  count(word, sort = T) %>% 
  head(., n = 10)

# head(day_one$text, 20)
```

Another thing I measure is my vocabulary. I want to increase my vocabulary, although this will be difficult this year as I'm very actively trying to learn Norwegian. Is it improving? Hard to tell, I need to wait for this graph to mature and flatten.

```{r}
as_ats <- floor_date(ymd(as_at) - seq(0, 1800, by = 30), "month")



vocab_df <- data.frame()
for (i in 1:length(as_ats)) {
  vocab_df_temp <- tidy_text %>% 
  filter(date >= as_ats[[i]]) %>% 
  anti_join(tidy_text %>% filter(date < as_ats[[i]]), by = "word") %>% 
  select(-date) %>% 
  summarise(vocab = n_distinct(word)) %>% 
    mutate(date = as_ats[[i]])
  
  as_ats
  as_ats[[i]]
  vocab_df <- rbind(vocab_df, vocab_df_temp)
}

vocab_df %>% 
  filter(date >= ymd(20160901)) %>% 
  ggplot(aes(x = date, y = vocab)) +
  geom_line(colour = "#F98C0AFF") +
  theme_minimal() +
  theme(
        # axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        plot.title = element_text(face="bold", size = 20)) +
  labs(x = NULL, y = "Number of new words used each month",
       title = "Number of new words used each month \nis decreasing as expected") +
   scale_x_date(date_breaks = "1 month", date_labels = "%b %g") 
```

Kinda looks like March had a steeper decrease than expected.

Putting this on a log scale makes the March drop much starker.

```{r}


vocab_df %>% 
  filter(date >= ymd(20160901)) %>% 
  ggplot(aes(x = date, y = log(vocab))) +
  geom_line(colour = "#F98C0AFF") +
  theme_minimal() +
  theme(
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        plot.title = element_text(face="bold", size = 20)) +
  labs(x = NULL, y = "log(Number of new words used each month)",
       title = "Number of new words in March dropped \nfaster than expected",
       subtitle = "Expected rate of new words (linear model): dotted line") +
   scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  geom_smooth(method = "lm", se = F, linetype = "dashed", colour = "#000004FF", size = 0.5)
```

Or one could argue that March is the normal rate and it was in October and November 2016 that the rate was high and then it slowed down as the year turned. The dotted line shows a linear trend which means the slow down of new words is constant each month. 

```{r, include = F}
# tidy_text %>% 
#   mutate(date = floor_date(date, "month")) %>% 
#   group_by(date, word) %>% 
#   summarise(count = n()) %>% 
#   # gather(variable, value, - date) 
#   # filter(sentiment %in% c("positive", "negative")) %>% 
#   group_by(date) %>%
#   top_n(5) %>%
#   mutate(word = reorder(word, count))%>%
#   ggplot(aes(word, count, fill = date)) +
#   # scale_fill_manual(values = c("#000004FF", "#F98C0AFF")) +
#   geom_col(show.legend = FALSE) +
#   facet_wrap(~date, scales = "free_y") +
#   labs(y = NULL,
#        x = NULL,
#        title = "My most common positive and\nnegative words",
#        caption = "@tojyouso") +
#   coord_flip() +
#   theme_minimal() +
#   theme(
#         # axis.text.y = element_blank(),
#         axis.title.x = element_blank(),
#         axis.ticks.y = element_blank(),
#         panel.grid = element_blank(),
#         plot.title = element_text(face="bold", size = 20))
```

### What kind of feelings do my words engender?

The `tidytext` package allows us to do some sentiment analysis. In simple terms, each word is assigned to an emotion and that emotion is categorised as positive or negative. I then take the difference between the number of positive words and the number of negative words to get a sentiment score. Therefore if the score was positive, I wrote more positive than negative words that day.

*NB: the sentiment analysis below only looks at individual words so a sentence like `I am not happy` will be positive as `happy` is a positve word. I had trouble breaking the journal entries into sentences for sentence level sentiment analysis so we'll have to make do with this for now.*

```{r}
# find out how mnay words are written each day to weight the sentiment
word_count <- tidy_text %>% 
  group_by(index = date) %>% 
  count()


tidy_text %>% 
  inner_join(get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", 
                        "negative"))) %>%
  mutate(method = "NRC") %>% 
  count(method, index = date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  left_join(word_count, by = "index") %>% 
  mutate(sentiment = sentiment / n) %>% 
  ggplot(aes(index, weight = sentiment, fill = sentiment > 0)) +
  geom_bar() +
  scale_fill_manual(values = c("#000004FF", "#F98C0AFF")) +
  labs(x = NULL, y = "Sentiment of words written daily",
       title = "I'm generally quite positive!",
       subtitle = "Orange bars are positive days and black are negative",
        caption = "@tojyouso") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %g") +
  # theme_ipsum(grid = "Y") +
  theme_minimal() +
  theme(
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20),
        legend.position = "none") 
```

Turns out I'm usually positive - probably because I've been blessed with a lot of good things in my life. I checked what happened at the end of October 2016 where there is a small cluster of negativity - it was when my wife AND my mum were ill :(. The negative days are quite sporadic and it's rare to see more than one in a row. That makes me happy, it means there isn't some underlying unhappiness. The fact that there aren't clusters of bad days also suggests that things that make me sad or angry or experience other negative emotions are probably not that big a deal if they only last one day. That's an important realisation and one I'll keep in mind in the future when I'm having a bad day.

There are also other emotions that the sentiment analysis brought out. I played with the chart for quite some time but I still think it is too busy. I did manage to arrange positive sentiments on the left and negative on the right!

```{r}

nrc_sentiments <- get_sentiments(("nrc"))

nrc_sentiments$sentiment <- factor(nrc_sentiments$sentiment,
                                   levels = c("positive", "negative", "joy", "sadness",
                                              "trust", "anger",  "surprise", "disgust",
                                              "anticipation", "fear"))
tidy_text %>% 
  inner_join(nrc_sentiments) %>% 
  # filter(sentiment %in% c("positive", 
                        # "negative"))) %>%
  # mutate(method = "NRC") %>% 
  rename(index = date) %>% 
  group_by(index, sentiment) %>% 
  summarise(count = n()) %>% 
  left_join(word_count) %>% 
  ungroup(index) %>% 
  mutate(index = floor_date(index, "month")) %>% 
  group_by(index, sentiment) %>% 
  summarise(count = sum(count), n = sum(n)) %>% 
  mutate(count = count / n) %>%
  ggplot(aes(index, count, group = sentiment, colour = sentiment)) +
  geom_line(show.legend = F) +
  scale_colour_manual(values = rep(c("#F98C0AFF", "#000004FF"), 5)) +
  theme_minimal() +
  facet_wrap(~sentiment, ncol = 2,  scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20)) +
  labs(x = NULL, y = NULL,
       title = "Breakdown of one-word-sentiment by month",
       # subtitle = "",
        caption = "@tojyouso") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %g") 
```

The positive emotions are all highly correlated with the peak in December 2016 and trough the next month. The negative words are all a bit different. The spike in Feb of disgust is interesting and I spent October being angry and sad (that's probably driven by the end of October times when my wife and mum were ill). I will need to explore February's disgust.

I can also show which of my most common words contribute most to the positive and negative sentiments. `love`, `happy` and `god` are my most common positive words :). I do write `Thank God` quite often! Money is quite high up there too haha and so is sex ;). 

```{r}
nrc_word_counts <- tidy_text %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

# nrc_word_counts

nrc_word_counts %>%
  filter(sentiment %in% c("positive", "negative")) %>% 
  group_by(sentiment) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  scale_fill_manual(values = c("#000004FF", "#F98C0AFF")) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = NULL,
       x = NULL,
       title = "My most common positive and\nnegative words",
       caption = "@tojyouso") +
  coord_flip() +
  theme_minimal() +
  theme(
        # axis.text.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face="bold", size = 20))

# inferno(5)
```

I can also use my new favourite calendar plot to see when I write the most positive words. Ultimately, I want to be able to click on a date and see what notes I wrote there but that is way beyond my current ability right now. 

```{r}
nrc_word_counts <- tidy_text %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>% 
  mutate(method = "NRC") %>% 
   count(method, index = date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  # rename(date = index) %>% 
  left_join(word_count, by = c("index")) %>% 
  mutate(sentiment = round(100 * sentiment / n),
         sentiment = ifelse(is.na(sentiment), 0, sentiment))

ggcal(nrc_word_counts$index, nrc_word_counts$sentiment) +
  scale_fill_viridis(option = "B", na.value = "#ffffff") +
  labs(title = "Sentiment of words written in my journal",
       # subtitle = "Red is positive",
       caption = "@tojyouso") +
  theme( plot.title = element_text(face="bold", size = 20),
         panel.grid = element_blank())
```

Lastly, a text analysis would not be complete without a word-cloud.

```{r}
tidy_text %>% 
  inner_join(get_sentiments("nrc") %>% filter(sentiment %in% c("positive", "negative"))) %>% 
  count(word, sentiment, sort = T) %>% 
  reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>% 
  wordcloud::comparison.cloud(colors = c("#000004FF", "#F98C0AFF"),
                   max.words = 1000, scale = c(4, 0.1), title.size = 0.00001)

```

## Future work

There were a few things I wanted to do but ran out of time and this post was getting quite long. I would like to explore the sentence sentiment analysis. I'd also like to explore how the words I write are related. Which words frequently appear together for example.

The Day One app also records location and weather with each note. It would be good to explore these at some point.

Now that I've done this for my Day One journal, I want to apply this to all other text based files in my life - WhatsApp conversations, text messages, twitter feeds. There's a lot out there that is very much accessible and it will be fun to see what I can learn from them.

## Final words

This was by far the most fun analysis project I've done so far. Not only was programming and writing the blog post fun, going back through old diary entries was really interesting. I wanted to put a bit more out on the blog but a lot of it is very personal as you can imagine. 

I've only been journalling for a very short time and I can't wait to see what this blog post will look like when I update it at the end of the year.

I showed this to my wife and she said it really captured who I am - someone who loves God, his family and friends and is happy! My three top positive words :).

If you have any questions on how I did any of the above, get in touch!

